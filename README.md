# Anthropic API Proxy for Gemini & OpenAI Models ğŸ”„

**Use Anthropic clients (like Claude Code) with Gemini or OpenAI backends.** ğŸ¤

A proxy server that lets you use Anthropic clients with Gemini or OpenAI models via LiteLLM. ğŸŒ‰


![Anthropic API Proxy](pic.png)

## Quick Start âš¡

### Prerequisites

- OpenAI API key ğŸ”‘
- Google AI Studio (Gemini) API key (if using Google provider) ğŸ”‘
- [uv](https://github.com/astral-sh/uv) installed.

### Setup ğŸ› ï¸

1. **Clone this repository**:
   ```bash
   git clone https://github.com/1rgs/claude-code-openai.git
   cd claude-code-openai
   ```

2. **Install uv** (if you haven't already):
   ```bash
   curl -LsSf https://astral.sh/uv/install.sh | sh
   ```
   *(`uv` will handle dependencies based on `pyproject.toml` when you run the server)*

3. **Configure Environment Variables**:
   Copy the example environment file:
   ```bash
   cp .env.example .env
   ```
   Edit `.env` and fill in your API keys and model configurations:

   *   `ANTHROPIC_API_KEY`: (Optional) Needed only if proxying *to* Anthropic models.
   *   `OPENAI_API_KEY`: Your OpenAI API key (Required if using the default OpenAI preference or as fallback).
   *   `GEMINI_API_KEY`: Your Google AI Studio (Gemini) API key (Required if PREFERRED_PROVIDER=google).
   *   `PREFERRED_PROVIDER` (Optional): Set to `openai` (default) or `google`. This determines the primary backend for mapping `haiku`/`sonnet`.
   *   `BIG_MODEL` (Optional): The model to map `sonnet` requests to. Defaults to `gpt-4.1` (if `PREFERRED_PROVIDER=openai`) or `gemini-2.5-pro-preview-03-25`.
   *   `SMALL_MODEL` (Optional): The model to map `haiku` requests to. Defaults to `gpt-4.1-mini` (if `PREFERRED_PROVIDER=openai`) or `gemini-2.0-flash`.

   **Mapping Logic:**
   - If `PREFERRED_PROVIDER=openai` (default), `haiku`/`sonnet` map to `SMALL_MODEL`/`BIG_MODEL` prefixed with `openai/`.
   - If `PREFERRED_PROVIDER=google`, `haiku`/`sonnet` map to `SMALL_MODEL`/`BIG_MODEL` prefixed with `gemini/` *if* those models are in the server's known `GEMINI_MODELS` list (otherwise falls back to OpenAI mapping).

4. **Run the server**:
   ```bash
   uv run uvicorn server:app --host 0.0.0.0 --port 8082 --reload
   ```
   *(`--reload` is optional, for development)*

### Using with Claude Code ğŸ®

1. **Install Claude Code** (if you haven't already):
   ```bash
   npm install -g @anthropic-ai/claude-code
   ```

2. **Connect to your proxy**:
   ```bash
   ANTHROPIC_BASE_URL=http://localhost:8082 claude
   ```

3. **That's it!** Your Claude Code client will now use the configured backend models (defaulting to Gemini) through the proxy. ğŸ¯

## Model Mapping ğŸ—ºï¸

The proxy automatically maps Claude models to either OpenAI or Gemini models based on the configured model:

| Claude Model | Default Mapping | When BIG_MODEL/SMALL_MODEL is a Gemini model |
|--------------|--------------|---------------------------|
| haiku | openai/gpt-4o-mini | gemini/[model-name] |
| sonnet | openai/gpt-4o | gemini/[model-name] |

### Supported Models

#### OpenAI Models
The following OpenAI models are supported with automatic `openai/` prefix handling:
- o3-mini
- o1
- o1-mini
- o1-pro
- gpt-4.5-preview
- gpt-4o
- gpt-4o-audio-preview
- chatgpt-4o-latest
- gpt-4o-mini
- gpt-4o-mini-audio-preview
- gpt-4.1
- gpt-4.1-mini

#### Gemini Models
The following Gemini models are supported with automatic `gemini/` prefix handling:
- gemini-2.5-pro-preview-03-25
- gemini-2.0-flash

### Model Prefix Handling
The proxy automatically adds the appropriate prefix to model names:
- OpenAI models get the `openai/` prefix 
- Gemini models get the `gemini/` prefix
- The BIG_MODEL and SMALL_MODEL will get the appropriate prefix based on whether they're in the OpenAI or Gemini model lists

For example:
- `gpt-4o` becomes `openai/gpt-4o`
- `gemini-2.5-pro-preview-03-25` becomes `gemini/gemini-2.5-pro-preview-03-25`
- When BIG_MODEL is set to a Gemini model, Claude Sonnet will map to `gemini/[model-name]`

### Customizing Model Mapping

Control the mapping using environment variables in your `.env` file or directly:

**Example 1: Default (Use OpenAI)**
No changes needed in `.env` beyond API keys, or ensure:
```dotenv
OPENAI_API_KEY="your-openai-key"
GEMINI_API_KEY="your-google-key" # Needed if PREFERRED_PROVIDER=google
# PREFERRED_PROVIDER="openai" # Optional, it's the default
# BIG_MODEL="gpt-4.1" # Optional, it's the default
# SMALL_MODEL="gpt-4.1-mini" # Optional, it's the default
```

**Example 2: Prefer Google**
```dotenv
GEMINI_API_KEY="your-google-key"
OPENAI_API_KEY="your-openai-key" # Needed for fallback
PREFERRED_PROVIDER="google"
# BIG_MODEL="gemini-2.5-pro-preview-03-25" # Optional, it's the default for Google pref
# SMALL_MODEL="gemini-2.0-flash" # Optional, it's the default for Google pref
```

**Example 3: Use Specific OpenAI Models**
```dotenv
OPENAI_API_KEY="your-openai-key"
GEMINI_API_KEY="your-google-key"
PREFERRED_PROVIDER="openai"
BIG_MODEL="gpt-4o" # Example specific model
SMALL_MODEL="gpt-4o-mini" # Example specific model
```

## How It Works ğŸ§©

This proxy works by:

1. **Receiving requests** in Anthropic's API format ğŸ“¥
2. **Translating** the requests to OpenAI format via LiteLLM ğŸ”„
3. **Sending** the translated request to OpenAI ğŸ“¤
4. **Converting** the response back to Anthropic format ğŸ”„
5. **Returning** the formatted response to the client âœ…

The proxy handles both streaming and non-streaming responses, maintaining compatibility with all Claude clients. ğŸŒŠ

## Contributing ğŸ¤

Contributions are welcome! Please feel free to submit a Pull Request. ğŸ

## å¤šæ¸ é“é…ç½®ä¸æ¨¡å‹è·¯ç”±ï¼ˆé«˜çº§ç”¨æ³•ï¼‰ ğŸš¦

æœ¬ä»£ç†æ”¯æŒ**å¤šæ¸ é“APIè·¯ç”±**ï¼Œå¯é€šè¿‡æ¨¡å‹ååç¼€ `:æ¸ é“å` çµæ´»æŒ‡å®šä¸åŒAPIç«¯ç‚¹å’ŒKEYï¼Œé€‚ç”¨äºå¤šä¾›åº”å•†/å¤šè´¦å·/å¤šä»£ç†ç­‰åœºæ™¯ã€‚

### ç¯å¢ƒå˜é‡é…ç½®

åœ¨ `.env` æ–‡ä»¶ä¸­æ·»åŠ å¦‚ä¸‹å†…å®¹ï¼š

```dotenv
# é»˜è®¤æ¸ é“é…ç½®ï¼ˆå‘åå…¼å®¹ï¼‰
BASE_URL="https://gemini-balance.eqing.tech/openai/v1"
API_KEY="sk-UIpCcB7ic4xxxxxx8F5C68744"
GEMINI_API_KEY="sk-gemini-default"
OPENAI_API_KEY="sk-openai-default"
ANTHROPIC_API_KEY="sk-anthropic-default"

# æ–°å¢è‡ªå®šä¹‰æ¸ é“
CHANNEL_GEMINI2_BASE_URL="https://another-gemini-api.com/v1"
CHANNEL_GEMINI2_API_KEY="sk-gemini2-key"

CHANNEL_CLAUDE2_BASE_URL="https://another-claude-api.com/v1"
CHANNEL_CLAUDE2_API_KEY="sk-claude2-key"

# å…¶ä»–é…ç½®ä¿æŒä¸å˜
PREFERRED_PROVIDER="openai"
BIG_MODEL="openai/gemini-2.5-pro-cfp"
SMALL_MODEL="openai/gemini-2.5-flash"
DEBUG="true"
```

- `CHANNEL_<NAME>_BASE_URL` å’Œ `CHANNEL_<NAME>_API_KEY` ç”¨äºå®šä¹‰æ–°æ¸ é“ã€‚
- `<NAME>` ä¸åŒºåˆ†å¤§å°å†™ï¼Œè°ƒç”¨æ—¶ç»Ÿä¸€å°å†™ã€‚

### ä½¿ç”¨æ–¹æ³•

- **é»˜è®¤è¡Œä¸º**ï¼ˆä¸å¸¦æ¸ é“åç¼€ï¼‰ï¼š
  ```json
  { "model": "gemini/gemini-2.5-pro", ... }
  ```
  ä½¿ç”¨ `BASE_URL` å’Œ `API_KEY`ï¼ˆæˆ–å„è‡ªæ¨¡å‹ç±»å‹çš„ KEYï¼‰ã€‚

- **æŒ‡å®šæ¸ é“**ï¼ˆæ¨èï¼‰ï¼š
  ```json
  { "model": "gemini/gemini-2.5-pro:gemini2", ... }
  { "model": "anthropic/claude-3-opus:claude2", ... }
  ```
  è·¯ç”±åˆ°å¯¹åº”çš„ `CHANNEL_GEMINI2_BASE_URL`/`CHANNEL_GEMINI2_API_KEY` æˆ– `CHANNEL_CLAUDE2_BASE_URL`/`CHANNEL_CLAUDE2_API_KEY`ã€‚

#### curl ç¤ºä¾‹

```bash
# é»˜è®¤æ¸ é“
curl -X POST http://localhost:8082/v1/messages \
  -H "Content-Type: application/json" \
  -d '{ "model": "gemini/gemini-2.5-pro", "max_tokens": 1000, "messages": [{"role": "user", "content": "Hello"}] }'

# æŒ‡å®š gemini2 æ¸ é“
curl -X POST http://localhost:8082/v1/messages \
  -H "Content-Type: application/json" \
  -d '{ "model": "gemini/gemini-2.5-pro:gemini2", "max_tokens": 1000, "messages": [{"role": "user", "content": "Hello"}] }'

# æŒ‡å®š claude2 æ¸ é“
curl -X POST http://localhost:8082/v1/messages \
  -H "Content-Type: application/json" \
  -d '{ "model": "anthropic/claude-3-opus:claude2", "max_tokens": 1000, "messages": [{"role": "user", "content": "Hello"}] }'
```

### ä¸»è¦ç‰¹æ€§

1. **å®Œå…¨å…¼å®¹ litellm å‰ç¼€**ï¼šå¦‚ `gemini/`ã€`openai/`ã€`anthropic/`ï¼Œä¸å½±å“æ ¼å¼è¯†åˆ«ã€‚
2. **çµæ´»è·¯ç”±**ï¼šé€šè¿‡ `:æ¸ é“å` åç¼€ï¼Œä»»æ„æ¨¡å‹å¯è·¯ç”±åˆ°ä¸åŒAPIç«¯ç‚¹å’ŒKEYã€‚
3. **å‘åå…¼å®¹**ï¼šä¸æŒ‡å®šæ¸ é“æ—¶ï¼Œè¡Œä¸ºä¸åŸæœ‰ä¸€è‡´ã€‚
4. **å¤šè´¦å·/å¤šä»£ç†æ”¯æŒ**ï¼šé€‚åˆä¼ä¸šã€å›¢é˜Ÿã€ä¸ªäººå¤šAPIç®¡ç†ã€‚
5. **é…ç½®ç®€å•**ï¼šä»…éœ€åœ¨ `.env` æ–‡ä»¶ä¸­å¢åŠ æ¸ é“é…ç½®ã€‚

> âš ï¸ æ³¨æ„ï¼šæ¸ é“åç»Ÿä¸€å°å†™ï¼Œè°ƒç”¨æ—¶å¦‚ `:gemini2`ã€`:claude2`ã€‚

---
